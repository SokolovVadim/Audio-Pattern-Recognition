\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

%\usepackage[a4paper, margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{authblk}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{\textbf{Investigating Frame Size Effects on Mental State Classification\\ from the Androids Corpus}}


\author{Vadim Sokolov}
\affil{Department of Computer Science, University of Milan, Milan, Italy}
\date{}

\maketitle

\begin{abstract}
Mental state detection from speech is an important task in clinical settings, where non-invasive methods can support early diagnosis and monitoring. 
In this work, we investigate how varying frame sizes affect the accuracy of mental state prediction using audio from the Androids Corpus. 
We extract standard acoustic features (MFCCs, deltas, RMS) with varying temporal windows and evaluate performance using a linear classifier under a speaker-independent 5-fold protocol. 
Preliminary results show a substantial improvement in accuracy as frame size increases, confirming the hypothesis that mental states vary slowly. 
TODO: describe the results of further experiments with nonlinear models and additional acoustic descriptors.
\end{abstract}

\section{Introduction}
Mental health disorders such as depression affect millions worldwide. 
Automatic detection of such conditions from speech offers a non-invasive, scalable, and cost-effective screening tool. 
Speech contains both linguistic and paralinguistic cues that can correlate with psychological states.

In this study, we aim to explore how temporal framing in audio feature extraction affects classification performance. 
The assumption is that mental states change slowly over time, and thus longer frames might capture more relevant descriptors.

\section{Related Work and Motivation}
Previous work on the Androids Corpus \cite{androids2021} uses features extracted with OpenSMILE and evaluates classifiers using a speaker-independent 5-fold protocol. Other studies have employed deep learning, but often neglect the temporal resolution of acoustic features.

Our goal is to systematically explore different frame lengths to understand how temporal granularity affects classification. We hypothesize that longer frames improve performance by capturing more stable features.

\section{Methodology}

\subsection{Dataset}
We use the Androids Corpus, which contains recordings from interviews and reading tasks by individuals classified as either healthy controls or patients.
\begin{table}[h]
\centering
\caption{Summary of the Androids Corpus structure and contents.}
\resizebox{\linewidth}{!}{
%\begin{tabular}{p{4.2cm} p{8cm}}
\begin{tabular}{|c|c|}
\hline
\textbf{Component} & \textbf{Description} \\
\hline
\texttt{Reading-Task/} & 112 audio recordings of participants reading a fairy tale. Subfolders: \texttt{HC/} (54 files) and \texttt{PT/} (58 files). \\
\hline
\texttt{Interview-Task/audio/} & 116 full interview recordings. Subfolders: \texttt{HC/} (52 files) and \texttt{PT/} (64 files). \\
\hline
\texttt{Interview-Task/} \newline \texttt{audio\_clip/} & 874 segmented audio clips from interviews, distributed over 116 subdirectories (one per speaker). \\
%\texttt{fold-list.csv} & Lists of files for 5-fold speaker-independent evaluation. \\
%\texttt{Androids.conf} & OpenSMILE configuration file for audio feature extraction. \\
%\texttt{interview\_timedata.csv} & Turn-level segmentation metadata for the full interview recordings. \\
\hline
\texttt{Labels} & Each file is labeled by condition: \texttt{PT} (patient) or \texttt{C} (control). \\
\hline
\texttt{Naming convention} & \texttt{nn\_XGmm\_t.wav}, where fields encode speaker ID, condition, gender, age, and education level. \\
\hline
\end{tabular}
}
%\caption{Summary of the Androids Corpus structure and contents.}
\label{tab:androids_summary}
\end{table}


\subsection{Feature Extraction}
We extract the following features using \texttt{librosa}:
\begin{itemize}
    \item 13 MFCCs
    \item Delta and Delta-Delta of MFCCs
    \item Root Mean Square (RMS) Energy
\end{itemize}

We experiment with various frame sizes: 20ms, 30ms, 100ms, 250ms, 500ms, 1000ms, 5000ms, and 10000ms. 
We study 20s and 30s frame sizes to make sure the patterns no longer persist with drastically wide windows. 
All features are normalized using standard scaling.

\subsection{Classification}
We start with a logistic regression model and evaluate frame-level accuracy and F1 score. 
The dataset is split using a speaker-independent 5-fold division, consistent with the original baseline setup.
Implemented file-level majority voting like a BS2 baseline in the original paper.
Compared frame level against file level performance. TODO: add performance comparison.


\section{Experiments and Results}

\subsection{Evaluation Metrics}
We use:
\begin{itemize}
    \item Frame-level accuracy
    \item Frame-level F1 score
    \item Confusion matrix (TBD)
\end{itemize}

\subsection{Results}
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{../out/PerformansOfFrameSizeLogScale.png}
    \caption{Accuracy and F1 Score vs Frame Size (log-scale)}
    \label{fig:performance}
\end{figure}

Initial results show that performance improves with larger frame sizes, peaking around 10000â€“20000ms. See Figure \ref{fig:performance}.

% Linear model

\begin{table}[h]
\centering
\caption{Linear model performance.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Accuracy} & \textbf{F1-score}\\
\hline
20 & 0.6455 & 0.6278 \\
\hline
30 & 0.6506 & 0.6296 \\
\hline
100 & 0.6635 & 0.6337 \\
\hline
250 & 0.6583 & 0.6269 \\
\hline
500 & 0.6640 & 0.6300 \\
\hline
1000 & 0.6684 & 0.6296 \\
\hline
5000 & 0.7067 & 0.5829 \\
\hline
10000 & 0.7255 & 0.6400 \\
\hline
15000 & 0.7290 & 0.6849 \\
\hline
20000 & 0.7317 & 0.6786 \\
\hline
30000 & 0.7074 & 0.7074 \\
\hline
\end{tabular}
\label{tab:linear_model_perf}
\end{table}

% Random forest

\begin{table}[h]
\centering
\caption{Random forest performance.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Accuracy} & \textbf{F1-score}\\
\hline
20 & 0.6799 & 0.6115 \\
\hline
30 & 0.6829 & 0.6115 \\
\hline
100 & 0.6788 & 0.6027 \\
\hline
250 & 0.6661 & 0.5907 \\
\hline
500 & 0.6618 & 0.5945 \\
\hline
1000 & 0.6589 & 0.5957 \\
\hline
5000 & 0.6693 & 0.5799 \\
\hline
10000 & 0.6894 & 0.6006 \\
\hline
15000 & 0.6898 & 0.6398 \\
\hline
20000 & 0.6477 & 0.5925 \\
\hline
30000 & 0.6352 & 0.5873 \\
\hline
\end{tabular}
\label{tab:random_forest_perf}
\end{table}

% SVM

\begin{table}[h]
\centering
\caption{SVM performance.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Accuracy} & \textbf{F1-score}\\
\hline
20 & 0.6635 & 0.5833 \\
\hline
30 & 0.6736 & 0.5908 \\
\hline
100 & 0.6824 & 0.5976 \\
\hline
250 & 0.6996 & 0.6053 \\
\hline
500 & 0.6890 & 0.5854 \\
\hline
1000 & 0.6916 & 0.5823 \\
\hline
5000 & 0.7186 & 0.5217 \\
\hline
10000 & 0.7576 & 0.6196 \\
\hline
15000 & 0.7245 & 0.6455 \\
\hline
20000 & 0.7575 & 0.6427 \\
\hline
30000 & 0.7556 & 0.7054 \\
\hline
\end{tabular}
\label{tab:svm_perf}
\end{table}

\section{Discussion}
Larger frames provide better performance, suggesting that mental state-related features are better captured over longer time spans. 
Short frames likely introduce variability and noise.

TODO:
\begin{itemize}
    \item Train nonlinear models (Random Forest, SVM, MLP)
    \item Add fundamental frequency and harmonicity-based features
    \item Perform feature importance analysis across frame sizes
\end{itemize}

\subsection{Feature importance analysis}
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{../out/feature_imp_1000ms.png}
    \caption{Feature importances from Random Forest model.}
    \label{fig:feature_importance}
\end{figure}

Directly extracted and visualized feature importances. 
Rms among the top features. 
That could indicate energy is a good mental state marker.

\begin{table}[h]
\centering
\caption{Feature importance analysis.}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Top Feature} & \textbf{2nd Feature} & \textbf{3rd Feature}\\
\hline
20 & mfcc\_2 & mfcc\_1 & rms \\
\hline
30 & mfcc\_2 & mfcc\_1 & rms \\
\hline
100 & mfcc\_2 & mfcc\_1 & rms \\
\hline
250 & mfcc\_2 & mfcc\_1 & rms \\
\hline
500 & mfcc\_1 & mfcc\_2 & rms \\
\hline
1000 & mfcc\_1 & mfcc\_2 & rms \\
\hline
5000 & mfcc\_2 & mfcc\_1 & rms \\
\hline
10000 & mfcc\_2 & mfcc\_1 & rms \\
\hline
15000 & mfcc\_1 & mfcc\_2 & rms \\
\hline
20000 & mfcc\_2 & mfcc\_1 & mfcc\_13 \\
\hline
30000 & mfcc\_2 & mfcc\_1 & mfcc\_6 \\
\hline
\end{tabular}
\label{tab:feaure_importance}
\end{table}


Frome the table INSERT TABLE WITH FEATURE IMPORTANCE one can see that the RMS is one of the important features. 
I moves from top 3 features to 4th place for the frame size 20s and 30s.
When we compute feature importances from a Random Forest using \texttt{.feature\_importances\_}, what we're actually getting is the Mean Decrease in Impurity (MDI). 
Impurity refers to how mixed the class labels are in a node.
Higher MDI equals to a fact that feature was used more often and split more samples while significantly reducing impurity thus, 
more important.


\subsection{Performance of the classifiers with added features}

% linear

\begin{table}[h]
\centering
\caption{Linear model performance with added features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
20 & 0.6695 & 0.6248 & 0.7415 & 0.6433 \\
\hline
30 & 0.6718 & 0.6257 & 0.7542 & 0.6667 \\
\hline
100 & 0.6820 & 0.6318 & 0.7669 & 0.6746 \\
\hline
250 & 0.6746 & 0.6225 & 0.7627 & 0.6627 \\
\hline
500 & 0.6767 & 0.6245 & 0.7350 & 0.6310 \\
\hline
1000 & 0.6895 & 0.6356 & 0.7301 & 0.6164 \\
\hline
5000 & 0.7272 & 0.6756 & 0.7791 & 0.6885 \\
\hline
10000 & 0.7274 & 0.6721 & 0.7630 & 0.6444 \\
\hline
15000 & 0.7428 & 0.7138 & 0.7071 & 0.6420 \\
\hline
20000 & 0.6877 & 0.6489 & 0.6463 & 0.5672 \\
\hline
30000 & 0.7133 & 0.6993 & 0.7167 & 0.6909 \\
\hline
\end{tabular}
}
\label{tab:linear_model_added_feat_perf}
\end{table}

% random forest

File-level accuracy evaluated as well. It was assesed by majority voting as in bs2 baseline.

\begin{table}[h]
\centering
\caption{Random forest performance with added features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
20 & 0.6820 & 0.6290 & 0.7966 & 0.6923 \\
\hline
30 & 0.6849 & 0.6281 & 0.7966 & 0.6883 \\
\hline
100 & 0.6813 & 0.6224 & 0.7839 & 0.6752 \\
\hline
250 & 0.6703 & 0.6130 & 0.7585 & 0.6460 \\
\hline
500 & 0.6684 & 0.6144 & 0.7393 & 0.6303 \\
\hline
1000 & 0.6715 & 0.6272 & 0.7168 & 0.6279 \\
\hline
5000 & 0.7437 & 0.7087 & 0.8023 & 0.7302 \\
\hline
10000 & 0.7495 & 0.7162 & 0.8148 & 0.7475 \\
\hline
15000 & 0.7399 & 0.7239 & 0.7576 & 0.7000 \\
\hline
20000 & 0.6957 & 0.6883 & 0.7317 & 0.7027 \\
\hline
30000 & 0.7733 & 0.7792 & 0.8000 & 0.7931 \\
\hline
\end{tabular}
}
\label{tab:random_forest_added_feat_perf}
\end{table}

% svm

\begin{table}[h]
\centering
\caption{SVM performance with added features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
20 & 0.6774 & 0.5848 & 0.7873 & 0.6694 \\
\hline
30 & 0.6849 & 0.6022 & 0.7992 & 0.6749 \\
\hline
100 & 0.7169 & 0.6154 & 0.8263 & 0.6963 \\
\hline
250 & 0.7044 & 0.5912 & 0.8263 & 0.6822 \\
\hline
500 & 0.6893 & 0.5662 & 0.7949 & 0.6190 \\
\hline
1000 & 0.6903 & 0.5646 & 0.7876 & 0.6000 \\
\hline
5000 & 0.7465 & 0.6573 & 0.8140 & 0.6735 \\
\hline
10000 & 0.7495 & 0.6790 & 0.8000 & 0.6897 \\
\hline
15000 & 0.7428 & 0.6942 & 0.7273 & 0.6494 \\
\hline
20000 & 0.7589 & 0.6806 & 0.7317 & 0.6071 \\
\hline
30000 & 0.7333 & 0.7059 & 0.7333 & 0.7037 \\
\hline
\end{tabular}
}
\label{tab:svm_added_feat_perf}
\end{table}

\section{PCA analysis}

PCA analysis is used to reduce the number of features and therefore address the curse of dimensionality. 
We are preserving 95\% of variance to transform the dataset and get less uncorrelated "principal components" that preserve most of the variance.
For example, instead of 42 extended features we got 34-37 features.
We used 1000ms, 5000ms, 10000ms, 15000ms frames to study the effect of PCA on accuracy.

% linear

\begin{table}[h]
\centering
\caption{Linear model performance with PCA-reduced features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{PCA} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
1000 & no & 0.6895 & 0.6356 & 0.7301 & 0.6164 \\
\hline
1000 & yes & 0.6712 & 0.6131 & 0.7522 & 0.6410 \\
\hline
5000 & no & 0.7272 & 0.6756 & 0.7791 & 0.6885 \\
\hline
5000 & yes & 0.7272 & 0.6767 & 0.7674 & 0.6774 \\
\hline
10000 & no & 0.7274 & 0.6721 & 0.7630 & 0.6444 \\
\hline
10000 & yes & 0.7216 & 0.6734 & 0.7556 & 0.6667 \\
\hline
15000 & no & 0.7428 & 0.7138 & 0.7071 & 0.6420 \\
\hline
15000 & yes & 0.7312 & 0.7138 & 0.6869 & 0.6517 \\
\hline
\end{tabular}
}
\label{tab:linear_model_pca}
\end{table}


PCA for linear classifier gives slightly worse results than without PCA.
There are several reasons why PCA hurts linear model performance. 
First, PCA is unsupervised, it preserves the variance and doesn't preserve class-separability.
It can remove important discriminative information for the classifier.
Second, our features may already be informative, good in separating classes.
PCA might delute their effects.

% Random forest

\begin{table}[h]
\centering
\caption{Random Forest performance with PCA-reduced features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{PCA} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
1000 & no & 0.6715 & 0.6272 & 0.7168 & 0.6279 \\
\hline
1000 & yes & 0.6521 & 0.6050 & 0.7434 & 0.6375 \\
\hline
5000 & no & 0.7437 & 0.7087 & 0.8023 & 0.7302 \\
\hline
5000 & yes & 0.7375 & 0.6934 & 0.8256 & 0.7458 \\
\hline
10000 & no & 0.7495 & 0.7162 & 0.8148 & 0.7475 \\
\hline
10000 & yes & 0.7283 & 0.6981 & 0.7704 & 0.6931 \\
\hline
15000 & no & 0.7399 & 0.7239 & 0.7576 & 0.7000 \\
\hline
15000 & yes & 0.6965 & 0.6749 & 0.6869 & 0.6353 \\
\hline
\end{tabular}
}
\label{tab:random_forest_pca}
\end{table}

% svm

\begin{table}[h]
\centering
\caption{SVM performance with PCA-reduced features.}
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Frame size, ms} & \textbf{PCA} & \textbf{Frame-level Accuracy} & \textbf{Frame-level F1-score} & \textbf{File-level Accuracy} & \textbf{File-level F1-score} \\
\hline
1000 & no & 0.6903 & 0.5646 & 0.7876 & 0.6000 \\
\hline
1000 & yes & 0.6801 & 0.5669 & 0.7522 & 0.5692 \\
\hline
5000 & no & 0.7465 & 0.6573 & 0.8140 & 0.6735 \\
\hline
5000 & yes & 0.7484 & 0.6679 & 0.8256 & 0.7222 \\
\hline
10000 & no & 0.7495 & 0.6790 & 0.8000 & 0.6897 \\
\hline
10000 & yes & 0.7399 & 0.6723 & 0.7704 & 0.6437 \\
\hline
15000 & no & 0.7428 & 0.6942 & 0.7273 & 0.6494 \\
\hline
15000 & yes & 0.7399 & 0.7020 & 0.7374 & 0.6750 \\
\hline
\end{tabular}
}
\label{tab:svm_pca}
\end{table}

Effect of PCA on File-level accuracy.
For linear classifier, PCA improved results only at short frame size of 1000ms.
For Random forest, PCA improved the results at shorter durations of 1000ms, 5000ms, possibly reducing overfitting.
For SVM, PCA was beneficial at medium and long frames of 5000ms, 15000ms, which is typical for high dimentional models.

To sum up, PCA is not always beneficial. 
For linear models, PCA removes useful signal unless there is strong redundancy.
For nonlinear models, PCA helps to reduce the noise and address the curse of dimensionality.

\section{Conclusion}
This paper presents an analysis of frame size on speech-based mental state classification. 
Our experiments show a clear performance trend in favor of longer frames, supporting the idea that slowly varying descriptors matter more. 
TODO: refine these findings.

\begin{thebibliography}{9}
\bibitem{androids2021}
Alessandro Vinciarelli, University of Glasgow et al. \textit{The Androids Corpus: A New Publicly Available Benchmark for Speech Based Depression Detection}. Interspeech 2023.

\bibitem{librosa}
Brian McFee et al. \textit{librosa: Audio and music signal analysis in Python}. Proceedings of the 14th python in science conference. 2015.

\bibitem{sklearn}
Pedregosa et al. \textit{Scikit-learn: Machine Learning in Python}. JMLR 2011.

\end{thebibliography}

\end{document}
